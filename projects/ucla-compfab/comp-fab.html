<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>computational fabrication</title>

		<link rel="stylesheet" href="../../dist/reset.css">
		<link rel="stylesheet" href="../../dist/reveal.css">
		<link rel="stylesheet" href="../../dist/theme/white.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="../../plugin/highlight/github.css">
		<style>
			figure {
				padding: 0;
				display: inline-block;
				margin: 0;
				position: relative;
			}

			figcaption {
				position: absolute;
				font-size: 30%;
				bottom: 1em;
				left: 0;
				/* background-color: yellow; */
				width: 100%;
			}

			/* for splitting into 2 */
			.split {
    			display: flex;
			}

			.col {
    			flex: 1;
			}

			/* for side-by-side code blocks */
			.column-left {
				flex: 50%;
				/* margin-left: -5vw; */
			}

			.column-right {
				flex: 50%;
				/* margin-left: 5vw; */
			}

			.top-left-header {
				position: relative; 
			}

			.phl {
				  position: absolute;
				  left: -5vw;
				  top: -2vh;
				  color: #706b84;
				  font-size: 28px;
				  z-index: 100;
			}

			.purp {
				background-color: #aeb3f7;
  				color: black;
			}

			.reveal pre {
				/* width: 35vw; */
				width: max-content;
				font-size: 14px;
			}

			.special-header {
				position: absolute;
				padding: 0px;
				top: 0px;
				left: 0px;
				z-index:500;
				color: #706b84;
				font-weight: normal;
				font-size: 32px;
				/* background-color: rgba(0,0,0,0.5) */
			}

			.special-body {
				margin: auto;
				position: absolute;
				top: 50%;
				left: 0%;
				/*-ms-transform: translate(-50%, 50%);*/
				transform: translate(0%, -50%);
			}

			.reveal blockquote {
				box-shadow: none;
				width: 90%;
			}

			blockquote {
				margin: 20px 0 30px;
				padding-left: 20px;
				border-left: 5px solid #FF6700;
				box-shadow: none;
			}

			/* .slides>section{
				width: 100%;
				height: 100%;
			} */

		</style>
	</head>
	
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-auto-animate data-background-image="data/teaser.jpg" data-background-position="right" data-background-size="50%">
					<div class="split">
						<div class="col">
							<h4 style="text-align: left;">Computational Fabrication</h4>
							<p style="text-align: left; font-size: .6em;">Blair Subbaraman</p>
							<p style="text-align: left; font-size: .6em; margin-top: -2vh">Machine Agency, University of Washington</p>
							<p style="text-align: left; font-size: .6em; margin-top: -2vh"> Slides: rb.gy/lgxu6r</p>
						</div>
					<br>
					<aside class="notes">
						Hi! I'm Blair. I worked at REMAP for a couple years from 2018-2020, where Jeff welcomed me into the world of theater despite my not knowing anything. Since then, I started a PhD at the Unviersity of Washington, where I'm now in my 4th year in the department of Human-Centered Design & Engineering. I'm going to present on some of my own research as it relates to digital & computational fabrication, or broadly, the process of making physical things with machines. In particular, I'll talk about connecting coding interfaces and computational fabrication tools as a way to broaden participation in both physical and digital production.
					</aside>
				</section>

				<section data-auto-animate data-background-image="data/teaser.jpg" data-background-position="right" data-background-size="50%">
					<h4 style="text-align: left;">Key Takeaways</h4>
					<p style="text-align: left; font-size: .6em;">- Seamless experiences aren't always better</p>

					<aside class="notes">
						And as I share some of these projects, I hope to convince you of a couple key ideas. The first is that in building computational tools for fabrication, the goal doesn't need to be an end-to-end seamless experience, at least not at first. There's this idea in popular culture as well as in research that we're working towards a sort of star trek Replicator type application, where matter is automatically compiled into fully working objects. While I admit this seems pretty cool, I think the reality is that there are too many niches of possible users of computational fabrication to
						cater to them all with a single tool. And in fact, I think that overly focusing on interfaces in which you just press 'start' is really limiting in how we can employ fabrication in new & exciting ways. Part of what I'm interested in is how we can reduce the threshold for users to modify and make seamless experiences for their unique use case. 
					</aside>
				</section>

				<section data-auto-animate data-background-image="data/teaser.jpg" data-background-position="right" data-background-size="50%">
					<h4 style="text-align: left;">Key Takeaways</h4>
					<p style="text-align: left; font-size: .6em;">- Seamless experiences aren't always better</p>
					<p style="text-align: left; font-size: .6em;">- It matters who is using the tool, and how</p>

					<aside class="notes">
						To that point, taking into account who is using the tool and why is a productive way to build new computational fabrication systems. The needs of someone designing electronic circuits and, say, a ceramicist wanting to 3D print with clay are quite different, and each person brings with them unique existing expertise. Accounting for and incorporating these differences can lead to divergent fabrication machines and interfaces.

						Maybe these takeaways lack context for now, but I'll try to hammer them home and bring some nuance to them as they come up over the course of this talk.
					</aside>	
				</section>

				<section data-background-video="data/mohr-plotter.mp4">
					<aside class="notes">
						I wante to start with a briefly historical anecdote. This is a snippet from a documentary by IBM in the 1970s. It shows the work process of Manfred Mohr, a German artist who was a part of the first wave of artists who gained access to computers to make visual art. Here we see him programming, which at that time was not done at a screen but rather with pen and paper, making flowcharts and then creating physical punched cards which were read by the computer. We then see Mohr walk to a separate area and sit down at this  screen. This isn't actually a computer, which were still the size of entire rooms, but it's just a screen that displays the results of a computers calculation. We can see the output of Mohr's program begin to appear, which is showing various rotations of a cube. At this stage, Mohr can decide if he likes the results, or if he'd like to go back and edit the program to make something different. If it passes his scrutiny, then the piece can be physically drawn using a pen plotter. This is a drawing machine that can move left, right, up, and down around a flat surface. Both the computer and the plotter were, at the time, an expensive resource, so the stakes are pretty high here to create something you actually liked.
					</aside>
				</section> 

				<section data-auto-animate>
					<h4>Computation & Fabrication, Then & Now</h4>
					<div class="split">
						<div class="col">
							<figure>
								<img height=250 data-src="data/punching-cards.png">
								<figcaption>Punching computer cards</figcaption>
							</figure>
						</div>

						<div class="col">
							<figure>
								<img height=250 data-src="data/first-sketch.png">
								<figcaption>Creating visuals with code</figcaption>
							</figure>
						</div>
					</div>

					<aside class="notes">
						I show this clip to bring some historical depth to our conversation around both computation & fabrication. This era was very 'fabrication first' in a sense, since there were limited graphical output options. These pen plotters are arguably some of the first digital fabrication machines being used in an artistic or design process. I want to compare Mohr's work process with how we might work today to make the same piece. With respect to computation, obviously a lot has changed, and how we interact with computers has changed drastically. If we were making Mohr's piece today, we could write code to immediately see results on our laptops and quickly make small, iterative changes to get the output we liked. And, there wouldn't necessarily be a pressure to physically draw what we make, beacuse we could much more easily share the image, or better yet, the code itself.
					</aside>
				</section>

				<section data-auto-animate>
					<h4>Computation & Fabrication, Then & Now</h4>
					<div class="split">
						<div class="col">
							<figure>
								<img height=200 data-src="data/punching-cards.png">
								<figcaption>Punching computer cards</figcaption>
							</figure>

							<figure>
								<img height=200 data-src="data/mohr-plotter.png">
								<figcaption>Changing plotter pens</figcaption>
							</figure>

						</div>

						<div class="col">
							<figure>
								<img height=200 data-src="data/first-sketch.png">
								<figcaption>Creating visuals with code</figcaption>
							</figure>

							<figure>
								<img height=200 data-src="data/plottertwitter.png">
								<figcaption>Plotter images shared on Twitter</figcaption>
							</figure>
						</div>
					</div>

					<aside class="notes">
						With respect to fabrication, there's also some major differences. Tabletop plotters are widely available for personal use, along with a host of other machines like 3D printers and laser cutters. In this sense, fabrication is more accessible today; but part of what I want to emphasize today is that this is only one limited dimension of accessibility. If we look at Mohr's interaction with the plotter, it's actually pretty similar to today. In Mohr's case, the computer wrote the data on a magnetic tape which was then connected to the plotter to execute. If we were fabricating something today, we would generate machine instructions on our laptops, put the file on an SD card, and then plug it into the machine to execute. Past a few dialog boxes and number sliders, we don't have much of a say in what the machine does, nor can we change the machine's behaviour, after pressing start.
					</aside>
				</section>

				<section data-auto-animate>
					<h4>Research Context</h4>
					<small><p><em>"Harnessing the precision of machines for the creativity of individuals"</em></p></small><br>

					<figure>
						<video style="height: 250px; margin-bottom: 3vh" loop src="data/plottertwitter.mp4"></video>
						<figcaption data-id="fig1">Twigg-Smith et al.</figcaption>
					</figure>

					<figure>
						<video style="height: 250px; margin-bottom: 3vh" loop src="data/imprimer.mp4"></video>
						<figcaption data-id="fig1">Tran O'Leary et al.</figcaption>
					</figure>

					<aside class="notes">
						The lab I'm in, called Machine Agency, does research around topics like digital fabrication, small-scale automation, and open source communities, and is broadly summarized by the tagline, "harnessing the precision of machines for the creativity of individuals". The research takes several forms, from qualitative investigations into how digital fabrication tools are used in the real-world, to building systems, and I want to provide a bit of context here on the sorts of things we've worked on in the past and where I'm coming from.
					</aside>

				</section>

				<section data-auto-animate>
					<h4>Research Context</h4>
					<small><p><em>"Harnessing the precision of machines for the creativity of individuals"</em></p></small><br>

					<figure>
						<video style="height: 300px; margin-bottom: 3vh" data-autoplay loop src="data/plottertwitter.mp4"></video>
						<figcaption data-id="fig1">Twigg-Smith et al.</figcaption>
					</figure>

					<figure>
						<video style="height: 200px; margin-bottom: 3vh" loop src="data/imprimer.mp4"></video>
						<figcaption data-id="fig1">Tran O'Leary et al.</figcaption>
					</figure>

					<aside class="notes">
						So for example, a labmate of mine, Hannah, looked at the artwork and processes that were being shared on Twitter under the hashtag 'PlotterTwitter', which is a pretty cool hashtag to check out if you've not seen it before. And a lot of what is being shared and discussed in these spaces are things like, trying different types of pens, or different types of paper, to get interesting results, and the sorts of things that are shared between users are tips and hacks to use the plotter in unintended ways. This goes back to the idea that a seamless experience with a machine isn't always better.
					</aside>

				</section>

				<section data-auto-animate>
					<h4>Research Context</h4>
					<small><p><em>"Harnessing the precision of machines for the creativity of individuals"</em></p></small><br>

					<figure>
						<video style="height: 200px; margin-bottom: 3vh" loop src="data/plottertwitter.mp4"></video>
						<figcaption data-id="fig1">Twigg-Smith et al.</figcaption>
					</figure>

					<figure>
						<video style="height: 300px; margin-bottom: 3vh" data-autoplay loop src="data/imprimer.mp4"></video>
						<figcaption data-id="fig1">Tran O'Leary et al.</figcaption>
					</figure>

					<aside class="notes">
						Another lab member, Jasper, has been working on an augmented reality interface for CNC milling. So here we can see the outline of the object that he is going to cut is projected down onto the material to be able to confirm the setup before actually cutting anything out.						
					</aside>
				</section>
				

				<section>
					<p><em>How can we support domain experts to creatively engage computer controlled machines?</em></p>

					<aside class="notes">
						For my own part in all of this, my research laregly focuses on how we can support artists, scientists, and other pracitioners who are already experts in their field to creatively engage computer controlled machines. Machines like 3D printers, laser cutters, and mills are becoming increasingly cheaper and widespread--I'll bet there's a makerspace in walking distance of your classroom right now full of these machines--but the ways we are made to use them are too often prescriptive, limiting our creative possibilities. I try to investigate this question at a couple of different levels in my work. This includes staging systems interventions for use in the real-world, as well as understanding the behaviour of existing communities to ground the development of future systems.
					</aside>
				</section> 

				<section data-auto-animate="">
					<h4>Overview</h4>
					<figure>
						<video style="width: 200px; margin-bottom: 3vh" loop src="data/slicer.mp4"></video>
						<figcaption data-id="fig1">Computational Fabrication</figcaption>
					</figure>

					<figure>
						<video style="width: 200px; margin-bottom: 3vh" src="data/cc-square.mp4"></video>
						<figcaption data-id="fig4">Creative Code</figcaption>
					</figure>

					<figure>
						<video style="width: 200px; margin-bottom: 3vh" loop src="data/line-vase-short.mp4"></video>
						<figcaption data-id="fig2">p5.fab</figcaption>
					</figure>


					<figure>
						<video style="width: 200px; margin-bottom: 3vh" src="data/pipette-speedup-square.mp4"></video>
						<figcaption data-id="fig3">Creative Automation</figcaption>
					</figure>

					
					<aside class="notes">
						To this end, in this talk I want to introduce two areas of physical and digital practice--computational fabrication and creative code--and then talk about two projects which intersect these practices.
					</aside>
				</section> 

				<section data-auto-animate>
					<h4>Overview</h4>
					<figure>
						<video style="width: 250px; margin-bottom: 3vh" data-autoplay loop src="data/slicer.mp4"></video>
						<figcaption data-id="fig1"><br>Computational Fabrication</figcaption>
					</figure>
					
					<figure>
						<video style="width: 250px; margin-bottom: 3vh" data-autoplay loop src="data/cc-square.mp4"></video>
						<figcaption data-id="fig4">Creative Code</figcaption>
					</figure>

					<figure>
						<video style="width: 200px; margin-bottom: 3vh" loop src="data/line-vase-short.mp4"></video>
						<figcaption data-id="fig2">p5.fab</figcaption>
					</figure>

					<!-- <br> -->

					<figure>
						<video style="width: 200px; margin-bottom: 3vh" src="data/pipette-speedup-square.mp4"></video>
						<figcaption data-id="fig3">Creative Automation</figcaption>
					</figure>

					<aside class="notes">
						First, I'll introduce some core ideas and practices of computational fabrication--and then I'll immediately complicate these core assumptions that are baked into existing software. In particular, I want to show how software tools for fabrication are meant create a physical part that is as faithful to the digital model as possible, which can become disconnected from exploring physical properties of materials.  

						Then, I'll jump from physical practice to digital practice to introduce creative coding, which is broadly the process of programming for expressive over functional purposes. Since Manfred Mohr's time, artists have developed many software tools to tailored to their creative pursuits. Put in conversation with digital fabrication practice, we can start to see opportunities for new sorts of fabrication interfaces. 
					</aside>
				</section> 

				<!-- <section data-auto-animate>
					<h4>Overview</h4>
					<figure>
						<video style="width: 200px; margin-bottom: 3vh" loop src="data/slicer.mp4"></video>
						<figcaption data-id="fig1">Maintaining Machines</figcaption>
					</figure>

					<figure>
						<video style="width: 300px; margin-bottom: 3vh" data-autoplay src="data/cc-square.mp4"></video>
						<figcaption data-id="fig4">Remixing Code</figcaption>
					</figure>

					<figure>
						<video style="width:200px; margin-bottom: 3vh" loop src="data/line-vase-short.mp4"></video>
						<figcaption data-id="fig2">p5.fab</figcaption>
					</figure>

					<figure>
						<video style="width: 200px; margin-bottom: 3vh" src="data/pipette-speedup-square.mp4"></video>
						<figcaption data-id="fig3">Duckbot</figcaption>
					</figure>

					<aside class="notes">
						Then, I'll jump from physical practice to digital practice to introduce creative coding, which is broadly the process of programming for expressive over functional purposes. Since Manfred Mohr's time, artists have developed many software tools to tailored to their creative pursuits, and we can see how creative coding benefits from large existing communities that share art and code online. Put in conversation with digital fabrication practice, we can start to see opportunities for new sorts of fabrication interfaces. 
					</aside>
				</section>  -->

				<section data-auto-animate>
					<h4>Overview</h4>
					<figure>
						<video style="width: 200px; margin-bottom: 3vh" loop src="data/slicer.mp4"></video>
						<figcaption data-id="fig1">Computational Fabrication</figcaption>
					</figure>

					<figure>
						<video style="width: 200px; margin-bottom: 3vh" src="data/cc-square.mp4"></video>
						<figcaption data-id="fig4">Creative Code</figcaption>
					</figure>

					<figure>
						<video style="width: 300px; margin-bottom: 3vh" data-autoplay loop src="data/line-vase-short.mp4"></video>
						<figcaption data-id="fig2">p5.fab</figcaption>
					</figure>

					<figure>
						<video style="width: 200px; margin-bottom: 3vh" src="data/pipette-speedup-square.mp4"></video>
						<figcaption data-id="fig3">Creative Automation</figcaption>
					</figure>

					<aside class="notes">
						Following some of these insights, I'll talk about a couple of systems that I've worked on. p5.fab is a javascript library which supports control of digital fabrication machines from a creative coding environment; I'll introduce the tool and discuss some reactions from artists who tested the system;
					</aside>
				</section> 

				<section data-auto-animate>
					<h4>Overview</h4>
					<figure>
						<video style="width: 200px; margin-bottom: 3vh" loop src="data/slicer.mp4"></video>
						<figcaption data-id="fig1">Computational Fabrication</figcaption>
					</figure>

					<figure>
						<video style="width: 200px; margin-bottom: 3vh" src="data/cc-square.mp4"></video>
						<figcaption data-id="fig4">Creative Code</figcaption>
					</figure>

					<figure>
						<video style="width: 200px; margin-bottom: 3vh" loop src="data/line-vase-short.mp4"></video>
						<figcaption data-id="fig2">p5.fab</figcaption>
					</figure>

					<figure>
						<video style="width: 300px; margin-bottom: 3vh" data-autoplay src="data/pipette-speedup-square.mp4"></video>
						<figcaption data-id="fig3">Creative Automation</figcaption>
					</figure>
					
					<aside class="notes">
						and finally, I'll briefly talk about a laboratory automation system developed for plant biologists to think about how alternative machine interfaces might be of interest across domains. While this example is related to science, the point here is more in generalizing a bit from computational fabrication of individual artifacts to creatively employing automation.
					</aside>
				</section> 

				<section>
					<section>
						<h3 style="text-align: left;">Computational Fab, Creative Code</h3>
						<!-- <p style="text-align: left;">Connecting digital & physical production</p> -->

						<aside class="notes">
							So, we'll start in the world of digital fabrication, peppering in some insights & takeaways from prior qualitative research along the way.
						</aside>
					</section>
				
				
					<section>
						<h4>Definitions</h4>

						<figure>
							<img height=300 data-src="data/gh.jpg">
							<figcaption>Using Grasshopper3D for computational design</figcaption>
						</figure>

						<figure>
							<img height=300 data-src="data/3d-printing.png">
							<figcaption>Digital fabrication with a 3D printer</figcaption>
						</figure>

						<figure>
							<img height=300 data-src="data/nervous.jpg">
							<figcaption>A computationally fabricated lamp from Nervous System</figcaption>

						</figure>

						<aside class="notes">
							Before diving into the nitty-gritty of digital fabrication, I'll untangle the terms 'computational design', 'digital fabrication', and 'computational fabrication'. Computational design can refer to a whole range of design practices that incorporate computational processes. This involves the use of programing to do things like create and modify form and structure, but computational design isn't so much one specific technical skill as way to design rule sets which produce multiple outcomes.

							Digital fabrication is a manufacturing process where a machine is controlled by a computer. Common digital fabrication machines today are 3D printers, laser cutters, and mills; increasingly, these machines are available to hobbyists, or are are made available in community contexts like MakerSpaces.

							Computational fabrication, then, is more or less chaining together of computational design and digital fabrication. It integrates programming, design, and digital fabrication to design forms then construct these forms using fabrication machines.
						</aside>
					</section>

					<section>
						<h4>Fabrication, Big & Small</h4>

						<figure>
							<img height=400 data-src="data/stuttgart.jpg">
							<figcaption>Research Pavilion, University of Stuttgart</figcaption>
						</figure>

						<figure>
							<img height=400 data-src="data/kinematic-dress.jpg">
							<figcaption>Kinematic Dress, Nervous System</figcaption>
						</figure>

						<aside class="notes">
							The principles of computational design can be combined with different machines to create objects across a range of scales, from the architectural to the tabletop. The left image here shows a robot arm constructing a computationally generated pavilion at the University of Stuttgart; on the right is the Kinematic Dress from the design studio Nervous system, where they came up simulation techniques to take a large 3D thing, a dress, and fold & flatten it into something that can be 3d printed in one piece.
						</aside>
					</section>

					<!-- <section>
						<h4>A Usual 3D Printing Workflow</h4>

						<figure>
							<img height=300 data-src="data/3dprinter.jpg">
							<figcaption>Diagram of a typical hobbyist 3D printer</figcaption>
						</figure>

						<aside class="notes">
							Let's take 3D printing as an example to understand a usual fabrication workflow. A 3D printer works by extruding heated plastic out of a small nozzle. The  
						</aside>
					</section> -->

					<section>
						<h4>A Usual 3D Printing Workflow</h4>

						<figure>
							<img height=300 data-src="data/rhino.jpg">
							<figcaption>Computer Aided Design (CAD)</figcaption>
						</figure>

						<figure>
							<video style="width: 300px; margin-bottom: 3vh" loop src="data/slicer.mp4"></video>
							<figcaption data-id="fig1">Computer Aided Manufacturing (CAM)</figcaption>
						</figure>

						<figure>
							<img height=300 data-src="data/benchy-print.jpg">
							<figcaption>Computer Numeric Control (CNC)</figcaption>
							
						</figure>

						<aside class="notes">
							Let's take 3D printing as an example to understand a usual fabrication workflow. First, you need to design a model to print. This is typically done in computer aided design or a similar environment; maybe people have used on of these before, and common examples are Rhino3D, Blender, or SolidWorks. Then, we need to use this geometry to plan the machines toolpaths, or the path it will take as it moves through space. This is done by importing the model in a computer-aided manufacturing, or CAM, software. For 3D printing, this is called the slicer, as it is intended to divide a model into a series of contours to be printed layer-by-layer. The slicer will produce machine instructions called g-code, or geometry code, which can be exectued on the machine.   
						</aside>
					</section>

					<section>
						<h4>A Unusual 3D Printing Workflow</h4>
						<figure>
							<img height=400 data-src="data/tactum.gif">
							<img height=400 data-src="data/tactum.jpg">
							<figcaption><em>Tactum</em>, Gannon et al.</figcaption>
						</figure>

						<aside class="notes">
							It's worth noting that prior work has taken issue with this workflow, especially around the modeling stage. As an example of this, here's a system called Tactum, intended to create 3D printed wearables directly on your body. They project the design directly onto your arm and you can manipulate the geometry with gestures to see what it will look like before 3D printing it.
						</aside>
					</section>

					<section>
						<h4>Promise vs. Practice </h4>

						<figure>
							<img height="300" src="data/cat-model.png">
							<figcaption>Expected fabrication outcome based on model</figcaption>
						</figure>
						
						<figure>
							<img height="300" src="data/spaghetti.jpg">
							<figcaption>Actual outcome from 3D printing (<em>from r/FixMyPrint</em>)</figcaption>
						</figure>
						<aside class="notes">
							But even with new and intuitive modeling techniques, things often don't go as planned when you go to physicall manufacture something. There will often be problems with the geometry, and there are a bunch of physical constraints like not being to print models with sharp angles because each layer needs to be supported from underneath. And unlike Mohr's plotter that we saw earlier, which was maintained in a well-funded laboratory by a group of technicians, most people 3D printing today are using them in their homes or studios.The workflow we saw assumes that machines will obediently execute exactly what we tell it to, but that isn't always the case. We see then this kind of glaring disconnect between digital tools and the physical process of fabrication.
						</aside>
					</section>

					<section>
						<h4>Promise vs. Practice </h4>
						<figure>
							<img width="1000" src="data/inner-ear.png">
							<figcaption>Physicalizing audio data in custom sculptural
								forms</figcaption>
						</figure>

						<aside class="notes">
							These problems become particularly acute in computational fabrication processes. This is an example from a past project I worked on, where a group of designers wanted to use audio data to drive the generation of clay sculptural forms. The raw data is used to start a digital simulation, and the resulting 3D form is printed using a clay 3D printer. The successful integration of computational methods and physical manufacturing here is dependent on establishing correspondences between digital instructions and physical outcomes, but these connections aren't well mapped. Most of the work here was in testing and tuning the simulation so that the resulting model was both printable and legible for their specific context. These software-driven fabrication workflows really require extensive software testing, tweaking, and optimization in response to machine and material behavior. 
						</aside>
					</section>
					

					<section>
						<h4>Promise vs. Practice </h4>
						<figure>
							<img height="300" src="data/stl-head.jpg">
							<figcaption>Models are saved as <code>stls</code>, which are just lists of triangles</figcaption>
						</figure>

						<figure>
							<img height="300" src="data/gcode.png">
							<figcaption>Machine instructions are saved as g-code</figcaption>
						</figure>

						<aside class="notes">
							And briefly, this disconnect between digital and physical reality extends all the way to the underlying representation of digital models. When you make a model in CAD, or find one online, the standard file format is an stl. This is just a list of triangles that define the boundary surface of your model; these triangles can be bigger or smaller depending on how detailed you model is and the resolution of whateve machine you're using. However, this isn't a very expressive file format; as we can increasingly print with more than one material, or muliple colors, there's no way to represent what's happening inside the object, which depending on the application can be just as important as the exterior. And g-code, which are the instructions that are sent to the machine, are basically just a list of coordinates to move to at a certain speed. Again, this language makes a lot of assumptions on what it is you want to do with the machine. There's no clean ways to, say, incorporate sensor data which can affect the machines motion at run-time. 
						</aside>
					</section>

					<section data-auto-animate>
						<p class="r-fit-text">Practitioners negotiate <b>digital software</b> with <b>physical practice</b>.</p>
						<aside class="notes">
							The end result is that pracitioners are made to reconcile digital software with a fundamentally physical practice. Crossing the digital/physical divide remains challenging, especially when developing products with novel materials, forms, or manufacturing contexts.
						</aside>
					</section>

					<section data-auto-animate>
						<p class="r-fit-text">Practitioners negotiate <b>digital software</b> with <b>physical practice</b>.</p>
						<p class="r-fit-text">How can we support a wider range of interactions with the machine?</p>
						<aside class="notes">
						From a systems design perspective, this analysis prompts us to think about how we can support a wider range of interactions with the machine, particularly ones that shifts our focus from the screen to the machine.
						</aside>
					</section>

					<!-- <section data-auto-animate>
						<p class="r-fit-text">Practitioners negotiate <b>digital software</b> with <b>physical practice</b></p>
						<small>
							<blockquote>
								I noticed [the clog] because I gradually had more and
								more under-extrusion. Which at first was I guess totally
								fine in my eyes, because it never printed totally perfectly
								before... I tried all the things like settings in my slicer before I
								actually went for disassembling stuff, because it was
								also kind of scary. And it seemed like a lot of work. Now
								I know that it’s not that way. It’s quite easy, it just takes
								a couple of screws.
							</blockquote>
							- P1
						</small>
						<img width=90% src="data/extrusion.png">
						<aside class="notes">
							As just one example of this, I really like this story from one of our interview participants. They noticed that their printer was under-extruding, meaning less filament was being deposited than necessary as shown in this image. This didn't seem to be an issue at first, because they say their printer never printer perfectly anyways. To fix the issue, they edited software settings, but this obsucred the root problem, which was in fact a clog. They say:
							
							quote

							From a systems design perspective, this analysis prompts us to think about how we can support a wider range of interactions with the machine, particularly ones that shifts our focus from the screen to the machine.
						</aside>
					</section> -->
					

					<!-- <section data-auto-animate>					
						<p>Routines | Repairs | Refinements | Reconciliations</p>
						<p>put a picture here</p>
						<aside class="notes">
							We conceptualized 4 main themes which we situate within digital fabrication practice.
							talk about main takeaways
						</aside>
					</section> -->

				</section>
				<!-- END MAINTENANCE	 -->

				<!-- START CODE -->
				<section>
					<!-- <section data-auto-animate>
						<h3 style="text-align: left;">Remixing Code</h3>
						<p style="text-align: left;">Understanding communities of creative practice</p>

						<aside class="notes">
							I want to put a pin in our conversation about digital fabrication for a second, and jump to a primarily digital practice, creative coding.
						</aside>
					</section> -->

					<section data-background-video="data/hexablob.mp4" data-background-video-loop>
						<aside class="notes">
							I want to put a pin in our conversation about digital fabrication for a second, and jump to a primarily digital practice, creative coding.  If you're unfamiliar with creative coding, it might look something like this. Creative coders create programs, called sketches, that generate visual output. The mission of these tools is broadly to make sketching with code as intuitive as sketching with a pen and paper. In this video, I'm editing a sketch posted to the website OpenProcessing. We can see that the effects of editing existing parameters in code can immediately be seen by running the sketch. Here, I'm editing the number of sides of a polygon and the number of bumps which are animated within it. 
							
							------------

							I could then choose to publish my edits as a new sketch; this repurposing of an existing artifact into something new is called remixing.
	
							------------

							Remixing facilitates this sort of iteration on existing code, but we have yet to understand how creative coders use remixing in practice. Moreover, given the focus on expressivity over functionality, we suspect that code reuse in creative coding is distinct from other programming contexts.
						</aside>
					</section> 

					<section>
						<h4>Creative Coding</h4>
						<figure>
							<img height=400 data-src="data/cc-tools.png">
							<figcaption>Open Source Software Tools for the Arts </figcaption>
						</figure>

						<figure>
							<img height=400 data-src="data/jacobs-paper.png">
							<figcaption>Li et al.</figcaption>
						</figure>

						<aside class="notes">
							There are lots of creative coding toolkits and libraries out there; some popular ones include p5.js, Processing, and OpenFrameworks. UCLA is actually a hub for development of these tools and communities, with Lauren McCarthy and Casey Reas in Design Media Arts being the creators of p5.js and Processing respectively. These tools have been developed by artists in alignment with their creative goals to overcome the limitations of the software available to them. They're are used by very large and active communities; p5.js, for example, is used by an estimated 10 million global users, for use in educational contexts through critically acclaimed artworks. Previous research has argued for pairing art production with tool production to foster broader participation in creative system development, and has investigated the software development practices of artists to guide technical collaborations. 
						</aside>
					</section> 

					<section>
						<h4>Connecting Creative Code & Digital Fabrication</h4>
						<div class="split">
							<div class="col">
								<figure>
									<img height=400 style="margin-bottom: 4vh" data-src="data/basic.png">
									<figcaption>BASIC code to control a plotter, 1964. <br> From <em>Form and Code</em>, Reas & McWilliams </figcaption>
								</figure>
							</div>

							<div class="col">
								<br><br>
								<figure>
									<pre style="width:30vw; margin-bottom: 4vh"><code class="javascript" data-trim data-line-numbers>
										function draw() {
											let sideLength = 10;
											for (let x = 0; x <= 90; x += 10) {
											  for (let y = 0; y <= 90; y += 10) {
												  rect(x, y, sideLength, sideLength);
											  }
											}
										}
									</code></pre>
									<figcaption>Drawing a grid of squares with p5.js, 2023</figcaption>
								</figure>
							</div>
						</div>
						<aside class="notes">
							These tools have come a long way from the programming tools that we saw Manfred Mohr was using for his plotter. You don't need to be a software engineer or have years computer science education in order to make what you want anymore. I would say that digital fabrication tools are currently in a place not unlike 1980s computer art in this regard, in that unless you're an expert dedicated to building new fabrication worklows, you're more or less stuck trying to bend the current tools and their resulting look & aesthetic.
						</aside>
					</section> 

					<section>
						<h4>Connecting Creative Code & Digital Fabrication</h4>
						<div class="split">
							<div class="col">
								<figure>
									<img height=200 style="margin-bottom:4vh" data-src="data/stl.png">
									<br>
									<img height=200 style="margin-bottom:4vh" data-src="data/gcode.png">
									<figcaption> Current model representations in CAD and CAM</figcaption>
								</figure>
							</div>

							<div class="col">
								<figure>
									<video style="height: 475px; margin-bottom: 3vh" data-autoplay loop src="data/p5fab-intro.mp4"></video>
									<figcaption>Direct toolpath design with <code>p5.fab</code></figcaption>
								</figure>
							</div>
						</div>
						<aside class="notes">
							So what might be gain from collapsing current CAD and CAM approaches to directly specify machine toolpaths? How does a programmatic representation and approach to computational fabrication change the sorts of interactions and artifacts we can create? 
						</aside>
					</section> 
				</section>

				<section>
					<section>
						<h3 style="text-align: left;">p5.fab</h3>
						<p style="text-align: left;"><em>Bridging Creative Code & Digital Fabrication</em></p>

						<aside class="notes">
							To investigate this question, I worked on p5.fab, which is a javascript library to control fabrication machines from the creative coding environment p5.js
						</aside>
					</section>

					<section data-background-video="data/line-vase.mp4"> 
						<aside class="notes">
							p5.fab tries to speak to the apparent tension between the precision & accuracy of machines like 3D printers, and the messy embodied practices which surround them. The video here shows a 3D printer whirring around-- plastic filament is melted in the hotend shown here, which is then extruded through the nozzle. We're printing these freehanging extrusions of a single line width across overextruded dots. This wouldn't be possible to print with off-the-shelf software for 3D printing, which is instead really good at optimizing the path the machine should take based on a digital model. In contrast, the printing the object shown here requires manual tuning to negotatiate speed, acceleration, and the amount of filament that's extruded. This requires testing and observing material behavior rather than reasoning about in a modeling file. 
						</aside>
					</section>
					

					<section data-transition="none-in none-out">
						<video style="outline: 5px solid white; outline-offset: -4px;" width=1000 data-autoplay src="data/fab-anim.mp4"></video>
						<aside class="notes">
							The idea is directly control the machine programatticaly to iteratively observe material outcomes. We can compose prints with methods like this-- the base fab object represents the machine, and carries machine data like the nozzle and filament radius, and size of the machine. 
						</aside>
					</section>
				

					<section data-transition="none-in none-out" >
						<video style="outline: 5px solid white; outline-offset: -4px;" width=1000 data-autoplay src="data/code-anim.mp4"></video>
						<aside class="notes">
							If we want to move to a position without depositing material, we can move retract, which will pull filament away from the nozzle to prevent unwanted oozing. Then we can move to an (x,y,z) coordinate on the bed.
						</aside>
					</section>

					<section data-transition="none-in none-out" >
						<video style="outline: 5px solid white; outline-offset: -4px;" width=1000 data-autoplay src="data/move-to-center.mp4"></video>
						<aside class="notes">
							For examnple, if we want to move to the center of the bed, we can access the machine's maxX and maxY properties.
						</aside>
					</section>

					<section data-transition="none-in none-out" >
						<video style="outline: 5px solid white; outline-offset: -4px;" width=1000 data-autoplay src="data/move-extrude.mp4"></video>
						<aside class="notes">
							We can print filament with the move extrude command. Here we might also specify a speed and specific extrusion amount. We provide access to other sorts of commands like this, 
						</aside>
					</section>

					<section data-transition="none-in none-out" >
						<video style="outline: 5px solid white; outline-offset: -4px;" width=1000 data-autoplay src="data/more-code.mp4"></video>
						<aside class="notes">
							and together they help us quickly build up 3 dimensional shapes, and specify interesting geometry.
						</aside>
					</section>

					<section data-auto-animate data-background-iframe="https://machineagency.github.io/p5.fab/editor/index.html" data-background-interactive>
						<aside class="notes">
							So for example, here's the editor-- we could open the Lissajous curve example, and visualize the toolpaths by changing some values
						</aside>
					</section>
		
					<section data-background-video="data/lissajous-print-4x.mp4">
						<aside class="notes">
							and the idea is to make things plug-n-play, so we connect the computer over wired usb to the printer and then can start streaming commands immediately to the printer 
						</aside>
					</section>

					<section>
						<h3>Motion Attribute Control</h3>
						<figure>
							<video style="height: 400px; margin-bottom: 3vh" data-autoplay loop src="data/velocity-painting.mp4"></video>
							<figcaption>Velocity painting with <code>p5.fab</code></figcaption>
						</figure>

						<figure>
							<img style="height: 400px; margin-bottom: 3vh" src="data/velocity-cube.jpg"></video>
							<figcaption>A printed cube with a checkered surface</figcaption>
						</figure>

						<aside class="notes">
							To have finer-grain control compared to standard tools, it's important to be able to not just specify geometry, but to have lower level control over how the extruder is moving between those points. In the print shown here we use an  approach called “velocity painting” to add a checkered pattern to one face of a cube. By speeding up or slowing down the print, the printer will deposit slightly different amounts of filament, leaving a visible texture on the exterior.
						</aside>
					</section>

					<section data-background-video="data/material-explorations.mp4">
						<aside class="notes">
							As I've been trying to demonstrate so far, fine-grain toolpath control coupled with iterative material exploration can be leveraged for expressive gain. We print a series of structures which explore toolpath geometry, motion, and extrusion. We reached each of these designs through a process of material exploration of various machine parameters. By tapping in to craft sensibilities fundamental to 3D printing practice, the goal is to encourage the operator to physically engage with the material and machine.

							For example, we can craft curved toolpaths which move off of the X-Y plane. Here, a sinusoidal toolpath allows filament to coil repeatedly and naturally. This produces a textured surface finish. Importantly, we can continuously manipulate extrusion amount, height, speed, and more in code to explore different material outcomes.  

							We also used the system to create unique interface. Normally, printing software will assume that you're printing on an unaltered, flat surface.  We used p5.fab to design a workflow to print directly onto an existing object elevated from the print bed. As an example, here we’re printing a decorative handle onto a cup. I'm aligning the nozzle to the desired position using a controls interface and incrementally lowering the nozzle until it just touches a piece of paper. We choose two points on the cup which define the handle endpoints and the precise geometry is generated on the fly, using the selected positions from the real world to set handle’s length. 
						</aside>
					</section>

					<section data-background-video="data/ca-1017.mp4">
						<aside class="notes">
							Moving to a programming environment means we can use other existing libraries and resources to build up interactive machine interfaces. Here's a quick example where I've connected a MIDI controller to be able to modify print speed and extrusion parameters in real-time-ish. So different knobs are mapped to different values in code, and we can tune prints as they're running. As we zoom in here, you'll see the printer slow down and start to drop filament from a height. This example uses a MIDI controller, but we could just as easily start to integrate computer vision or other sensor data to drive the machine.
						</aside>
					</section>

					<section data-auto-animate>
						<h4>Tensions & Opportunities in Building Community</h4>
						<img width=auto data-src="data/workshops.jpg">
						
						<aside class="notes">
							We tested p5.fab in two workshops; first with 3 professional artists working with code, and then with 3 makers experienced with 3D printing.  Across both our workshops, we found productive tensions and intersections between creative coding & 3D printing workflows. For example, the artists found waiting for a model to print much slower than their usual digital processes, even as makers found sending commands straight to the machine to be much faster than reverting to CAD and CAM software. What I also found interesting was how p5.fab made experts out of begginers and beginners out of experts. For example, the artists had never 3D printed and were able to immediately design & print complicated geometry. On the other hand, makers with minimal programming experience had to get a handle on coding, but were able to use the machine as a physical debugging platform to test their code.

						</aside>
						</section>

					<section data-auto-animate>
						<h4>Tensions & Opportunities in Building Community</h4>
						<small>
							<blockquote>
								As someone who considers 3D printing to be a bit daunting (CAD software always seems like a huge barrier to entry), it was so liberating to just get direct control of the machine. The layers of abstraction that CAD/slicer software add are really boring to me, so not having to deal with that is so fun...
							</blockquote>
						</small>
						<img width=auto data-src="data/workshops.jpg">
						
						<aside class="notes">
							I really liked this quote from one of the artist participants, who said ~quote~

							So, this was a real goal of the system; not to instantly make super fancy and slick artifacts, but to invite broader participation in digital fabrication. Going forward, I'm excited about the opportunities write and share code to create physical artifacts,
						</aside>
						</section>
				</section>
				<!-- END REMIXING -->

				<section>
					<section>
						<h3 style="text-align: left;">From Fabrication to Automation</h3>
						<!-- <p style="text-align: left;">Automation to support scientific exploration & beyond</p> -->

						<aside class="notes">
							but I want to transition here to show how these sorts of alternative machine interfaces can support the development of new workflows and experiences across domains.
						</aside>
					</section>

					<section data-auto-animate data-transition="none-out">
						<h4>Automation as a Tool for Creative Exploration</h4>
						<figure>
							<img height=400 src="data/two_circles.gif"></img>
							<figcaption><em>Two Circles</em>, Madeline Gannon</figcaption>
						</figure>

						<aside class="notes">
							And, similar to how creative code uses code as a creative medium, what I'm interested in with p5.fab and beyond is how we can sort of lift automation out of it's industrial legacies to build tools for creative exploration. This is a project from the designer Madeline Gannon called two circles-- it's a 2 meter googley eye attached to a 10,000 pound industrial robot, not unlike the robot arm I showed earlier for making architectural scale pavilions. There's a depth sensor here tracking people's positions, and the robot is programmed to inquisitively lean in when you do, and run away if you try to touch it. This sort of straightforward repurposing of the robot arm totally throws to the wind the conventional workflows for using these machines in pursuit of a more interactive experience.
						</aside>
					</section>

					<section data-auto-animate data-transition="none-in">
						<h4>Automation as a Tool for Creative Exploration</h4>
						<figure>
							<video style="height: 400px; margin-bottom: 3vh" data-autoplay loop src="data/choreorobotics.mp4"></video>
							<figcaption><em>Choreorobotics</em>, Madeline Gannon</figcaption>
						</figure>		
						
						<aside class="notes">
							Madeline is now working on a toolkit to control cable robots from the creative coding toolkit OpenFrameworks. Again, repurposing these robots for use in a very different context, here as a sort of room-scale installation, totally flips the way that we think about controlling these machines. Rather than coming up with a single design that's going to be run over and over again, we now want to be able to rapidly change and edit what the machine is doing.   
						</aside>
					</section>

					<section data-auto-animate>
						<h4>Automation as a Tool for Creative Exploration</h4>
						<figure>
							<video style="height: 400px; margin-bottom: 3vh" data-autoplay loop src="data/choreorobotics.mp4"></video>
							<figcaption><em>Choreorobotics</em>, Madeline Gannon</figcaption>
						</figure>		
						<p><small>requires...</small></p>
						<ul>
							<small> 
							<li>Modular, Low-cost, Extensible Hardware</li>
							<li>Human-centered Systems for Controlling Machines</li>
							</small>
						</ul>
	
						<aside class="notes">
							This picture of automation requires some distinct infrastructure. First, niche applications require niche tools, we can't take advantage of high volume sales & production to offset costs. Instead, we need modular, low-cost, and extensible hardware to customize one-off applications. 
							
							And after we build a machine, we need good ways of actually running it. Following the same line of thought as p5.fab or Madeline's robots here, we can think about writing code which generates machine instructions to allow reusability and flexibility running machines.
						</aside>
					</section>
					

					<section data-transition="none-in fade-out">
						<h4>Modular, Low-cost, Extensible Hardware</h4>
						<p><small>Open-source design for distributed manufacturing</small></p>
						<figure>
							<img height=300 data-src="data/jubilee.jpg">
							<figcaption>Jubilee: tool-changing machine</figcaption>
						</figure>
						<figure>
							<video style="height: 300px; margin-bottom: 3vh" data-autoplay loop src="data/tool-lock.mp4"></video>
							<figcaption>Design for precise, repeatable positioning</code></figcaption>
						</figure>

						<aside class="notes">
							To the first point, this is Jubilee; a multi-tool changing platform previously developed in our lab. Jubilee looks like a conventional 3D printer- it has a carriage that can move around in the x-y plane, and the bed can move up and down. It's interior volume is 300x300x300mm. It also has the ability to automatically pick up and change tools. That's shown on the right, where we see the carriage features this twist lock shaft. Each tool has a matching wedge plate, and the shaft can engage the tool and twist to lock it. By virtue of some clever mechanical design, these pickups are repeatable, so every time we grab a tool we can be sure its in the same place. 

							Jubilee is fully open-source, and designed to be fabricatable. This means it is made with parts that are readily available, or made with readily available tools & equipment, and there are at least 170 Jubilees in the world which we know of that have been independentely built.
						</aside>
					</section>

					<section data-transition="none-in none-out">
							<b>Modular, Low-cost, Extensible Hardware</b>
							<p><small>Digital fabrication of modular and customizable hardware</small></p>
							<figure>
								<img height=300 data-src="data/gigapan.jpg">
								<figcaption>gigapan microscopy</figcaption>
							</figure>
							<figure>
								<img height=300 data-src="data/jubilee-diagram.jpg">
								<figcaption>multi-tool processes</figcaption>
							</figure>

							<aside class="notes">
								Jubilee's tool-changing ability allows us to build up multi-tool processes. We can park multiple tools on Jubilee, and change between them as the machine runs. This allows us to build custom tools. Take this microscope tool shown here for example-- it's almost entirely 3D printed, with a few standard  screws and the like thrown in. In terms of electronics, Jubilee features both control boards for motion planning and controlling things like motors, as well as a Raspberry Pi, which if you've not heard of is a cheap computer. This means we can plug this USB microscope in to the Raspberry Pi to take & analyze images while moving it around.
							</aside>
						</section>
					
					<section data-transition="none-in fade-out">
						<b>Modular, Low-cost, Extensible Hardware</b>
						<p><small>Multi-tool processes</small></p>
						<figure>
							<video style="height: 300px; margin-bottom: 3vh" data-autoplay loop src="data/plotting.mp4"></video>
							<figcaption>Multi-color plotting</figcaption>
						</figure>

						<figure>
							<video style="height: 300px; margin-bottom: 3vh" data-autoplay loop src="data/benchy.mp4"></video>
							<figcaption>Multi-color printing</figcaption>
						</figure>

						<aside class="notes">
							Here's a couple examples of Jubilee being used, on the left to plot in multiple colors, and on the right the result of a multi-color print. These are both satisfying examples of using existing software with the machine, but they're still largely constrained by the usual digital fabrication steps we talked about earlier.
							
							A real advantage of Jubilee, though, is in  being able to create any custom tool you want.
						</aside>
					</section>

					<section data-auto-animate>
						<h4>Automation as a Tool for Creative Exploration</h4>
						<img width=auto data-src="data/creative-automation.jpg">
	
						<aside class="notes">
							In my own work, we've been thinking about automation in scientific contexts.

							For science, creative automation might look something like this: defining an experiment up front in a way that accommodates niche experimental design; being able to compile that experiment to instructions which can
							be run on a machine-- and maybe this requires physically configuring the machine for your custom applicatio-- and finally collecting data, where the operator--the scientist in this case-- can have some role to play at runtime.
	
							Now, I'm taking a brief detour into science, but the interest here is in how we can provide flexible infrastructure to build, customize, and run machines across a <i>range</i> of applications. Even though the application here is scientific exploration, I think there are some key insights here which are generalizable across other contexts.
						</aside>
					</section>

					<section>
						<b>The Duckbot</b>
						<p><small>Customizing Jubilee for plant biology</small></p>
						<img height=300 data-src="data/overhead.png">
						<img height=300 data-src="data/syringe-zoom.png">
						<img height=300 data-src="data/inoculation-zoom.png">

						<aside class="notes">
							We've been exploring an instantiation of Jubilee outfitted with tools for plant biology. Our collaborators work with duckweed, which are the aquatic plant you see here, and so we've called the resulting machine the duckbot. Biologists often want to grow different types in different environmental conditions to see their effect, so the configuration shown here uses different tools to move liquid, move duckweed, and then take pictures of the plant growing.

							A hard part of making custom tools though, is that we need a way to control them. Our usual ways of working with machines breaks down when we want to do things like move little plants around, rather than 3D print a cube. 

						</aside>
					</section>

					<section data-transition="none-in fade-out" data-auto-animate>
						<h4>Programmatic Control</h4>
						<pre><code class="python" data-line-numbers="1|2|3|4|5-7">	m = Machine()
	m.tool_change(syringe)
	m.move_to(x=media_reservoir.x, y=media_reservoir.y)
	syringe.aspirate(mL=20)
	well = well_plate("A1")
	m.move_to(x=well.x, y=well.y)
	syringe.dispense(mL=1.5)
	</code></pre>
						<video controls loop width=900 data-autoplay src="data/example-controls.mp4"></video>
						<aside class="notes">
							To that end, we can take a similar approach to p5.fab to control the machine.Here we're connecting to the machine and specify a certain tool to pick up-- we see the bed automatically dropping down 
							to accommodate the size of the syringe here. Then we can navigate over top a reservoir placed on the machine and aspirate a certain volume of media. Then, we can move to a specific well to dispense. 
						</aside>
					</section>

					<section>
						<h4>Programmatic Control</h4>
						<figure>
							<img height=400 src="data/jupyter.png"></img>
							<figcaption>By running code in a Jupyter notebook,</figcaption>
						</figure>
						<figure>
							<video style="height: 400px; margin-bottom: 3vh" data-autoplay loop src="data/image-plates-composed.mp4"></video>
							<figcaption>we can control the machine + tools in new ways</figcaption>
						</figure>
						<aside class="notes">
							The commands I just showed are being executed from a Jupyter notebook; if you haven't heard of Jupyter notebooks, it's a document where you can write and run small chunks of code and also write plain text notes. They're pretty common in data science, but they haven't really been used to control machines; we're pretty excited about how computational notebooks can faciliate iterative and exploratory machine control. We've been building up a library of tools paired with controls software to integrate while the machine is running; for example, this video on the right shows the machine picking up a camera tool. We can take advantage of some simple computer vision to identify the plants in the image, and differentially manipulate samples depending on, say, how big or healthy the plants are.
						</aside>
					</section>

					<section data-auto-animate>
						<h4>Heterogeneous Processes</h4>
						<figure>
							<video style="height: 300px; margin-bottom: 3vh" data-autoplay loop src="data/pipette-speedup-square.mp4"></video>
							<figcaption>Liquid tranfser</figcaption>
						</figure>

						<figure>
							<video style="height: 300px; margin-bottom: 3vh" data-autoplay loop src="data/inoculation-loop-pickup.mp4"></video>
							<figcaption>Duckweed manipulation</figcaption>
						</figure>

						<figure>
							<img style="height: 300px;" src="data/lm-loop.gif"></video>
							<figcaption>Image collection</figcaption>
						</figure>

						<aside class="notes">
							We used our duckbot to automate experiments, from computational design tools to plan experiements, through machine execution, and subsequent data analysis...
						</aside>
					</section>

					<section data-auto-animate>
						<h4>Heterogeneous Processes</h4>
						<figure>
							<video style="height: 225px; margin-bottom: 3vh" data-autoplay loop src="data/pipette-speedup-square.mp4"></video>
							<!-- <figcaption>cap</figcaption> -->
						</figure>

						<figure>
							<video style="height: 225px; margin-bottom: 3vh" data-autoplay loop src="data/inoculation-loop-pickup.mp4"></video>
							<!-- <figcaption>cap</figcaption> -->
						</figure>

						<figure>
							<img style="height: 225px;" src="data/lm-loop.gif"></video>
							<!-- <figcaption>cap</figcaption>							 -->
						</figure>

						<br>

						<figure>
							<img height=225 data-src="data/rhino.jpg">
							<!-- <figcaption>Computer Aided Design (CAD)</figcaption> -->
						</figure>
		
						<figure>
							<video style="width: 225px; margin-bottom: 3vh" loop src="data/slicer.mp4"></video>
							<!-- <figcaption data-id="fig1">Computer Aided Manufacturing (CAM)</figcaption> -->
						</figure>
		
						<figure>
							<img height=225 data-src="data/benchy-print.jpg">
							<!-- <figcaption>Computer Numeric Control (CNC)</figcaption> -->
						</figure>

						<aside class="notes">
							and, I know we've taken a bit of a scientific tangent here, but I want to take a moment to compare this to the usual digital fabrication workflow we saw earlier. Rather than one overarching pipeline from digital production to physical production, with Jubilee computational design and machine control are interwoven at each step of the process. And where before we were modeling and fabricating individual artiftacts, now we're stringing together complex workflows. 
	
							Going forward, I think systems like p5.fab or the Duckbot are just the beginning of an emerging paradigm to control fabrication machines using literate programs. 
						</aside>
					</section>
				</section>

				<!-- CONCLUSION -->
				<section>
					<section>
						<figure>
							<img height=300 src="data/mohr-plotter.png"></img>
							<figcaption>Mohr changing plotter pens </figcaption>
						</figure>

						<figure>
							<video style="height: 300px; margin-bottom: 3vh" data-autoplay loop src="data/tool-change.mp4"></video>
							<figcaption>Jubilee changing tools</figcaption>
						</figure>

						<aside class="notes">
							And as a parting thought, I just want you to prompt you to think about the sorts of things that Manfred Mohr could make with his plotter, versus the sorts of things we can make with 3D printers now, versus what we can make with machines like Jubilee and tools like p5.fab. And, in tandem with the technical infrastructure that we've been talking about, this sort of work implies a whole host of social infrastructure, like: how to share workflows rather than files, how to version control physical processes, and more.
						</aside>
					</section>

					
				</section>


				<section data-auto-animate data-background-image="data/teaser.jpg" data-background-position="right" data-background-size="50%">
					<h4 style="text-align: left;">Key Takeaways</h4>
					<p style="text-align: left; font-size: .6em;">- Seamless experiences aren't always better</p>
					<p style="text-align: left; font-size: .6em;">- It matters who is using the tool, and how</p>

					<aside class="notes">
						Coming back to the original goals I set out for this talk, we're equipped to take stock and bring a bit more nuance to the original takeaways.
					</aside>	
				</section>

				<section data-auto-animate data-background-image="data/teaser.jpg" data-background-position="right" data-background-size="50%">
					<h4 style="text-align: left;">Key Takeaways</h4>
					<p style="text-align: left; font-size: .6em;">- Seamless experiences aren't always better,</p>
					<p style="text-align: left; font-size: .6em;"><em>Tools that help practitioners navigate the physical/digital divide can expand the design space of computational fabrication.</em></p>
					<p style="text-align: left; font-size: .6em;">- It matters who is using the tool, and how.</p>

					<aside class="notes">
						I claimed that seamless experiences aren't always better, and through systems like p5.fab I tried to show how tools which help users navigate the physical/digital divide, rather than render it invisible, can expand the design space of computational fabrication. This isn't so much a claim against a seamless user experience, so much as an argument for the development of tools which allow users to make their own seamless experiences.
					</aside>	
				</section>

				<section data-auto-animate data-background-image="data/teaser.jpg" data-background-position="right" data-background-size="50%">
					<h4 style="text-align: left;">Key Takeaways</h4>
					<p style="text-align: left; font-size: .6em;">- Seamless experiences aren't always better</p>
					<p style="text-align: left; font-size: .6em;"><em>Tools that help practitioners navigate the physical/digital divide can expand the design space of computational fabrication.</em></p>
					<p style="text-align: left; font-size: .6em;">- It matters who is using the tool, and how</p>
					<p style="text-align: left; font-size: .6em;"><em>Acounting for unique user expertise can inform new approaches to machine design and control. </em></p>

					<aside class="notes">
						I also claimed that it matters who is using the tool, and how. For both p5.fab and the duckbot, grounding system development in actual practice leads to different fabrication interfaces. A computational notebook or a creative coding environment is a far cry from usual computer aided design software; as we engage more practitioners from different backgrounds, I think we can expect correspondingly diverse approaches to machine design and control.
					</aside>	
				</section>

				<section data-auto-animate data-background-image="data/teaser.jpg" data-background-position="right" data-background-size="50%">
					<div class="split">
						<div class="col">
							<h4 style="text-align: left;">Computational Fabrication</h4>
							<p style="text-align: left; font-size: .6em;">Blair Subbaraman</p>
							<p style="text-align: left; font-size: .6em; margin-top: -2vh">Machine Agency, University of Washington</p>
							<p style="text-align: left; font-size: .6em; margin-top: -2vh"> Slides: rb.gy/lgxu6r</p>
							<p style="text-align: left; font-size: .6em; margin-top: -2vh">blahblahblair.com</p>
						</div>
					<br>
					<aside class="notes">
						I'll stop there, and I'm interested in questions or comments that people have.
					</aside>
				</section>
			<!-- end divs -->
			</div>
		</div>

		<script src="../../dist/reveal.js"></script>
		<script src="../../plugin/notes/notes.js"></script>
		<script src="../../plugin/markdown/markdown.js"></script>
		<script src="../../plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
